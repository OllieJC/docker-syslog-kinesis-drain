<system>
  log_level ${LOG_LEVEL}
  suppress_config_dump true
</system>
<source>
  @type udp
  port ${UDP_PORT}
  bind "0.0.0.0"
  tag ${TOKEN}
  <parse>
    @type none
  </parse>
</source>
<source>
  @type tcp
  port ${TCP_PORT}
  bind "0.0.0.0"
  tag ${TOKEN}
  <parse>
    @type none
  </parse>
</source>
<source>
  @type http
  port ${PORT}
  bind "0.0.0.0"
  <parse>
    @type none
  </parse>
</source>
<filter ${TOKEN}>
  @type record_transformer
  enable_ruby
  <record>
    key ${Time.now.getutc.to_i.to_s + rand(36**32).to_s(36)}
    messageType "DATA_MESSAGE"
    owner ${(ENV.has_key?("CW_OWNER") ? ENV["CW_OWNER"] : "syslog-kinesis-drain").gsub('"', '\"')}
    logGroup ${(ENV.has_key?("CW_LOGGROUP") ? ENV["CW_LOGGROUP"] : "syslog").gsub('"', '\"')}
    logStream ${(ENV.has_key?("CW_LOGSTREAM") ? ENV["CW_LOGSTREAM"] : Socket.gethostname).gsub('"', '\"')}
    logEvents ${timestamp = Time.now.getutc.to_i.to_s; JSON.parse('[{"id":"0","timestamp":' + timestamp + ',"message":"' + record["message"].gsub("\n", ' ').gsub("\r", ' ').gsub('"', '\"') + '"}]')}
  </record>
  remove_keys message
</filter>
<match ${TOKEN}>
  @type kinesis_streams
  aws_key_id ${AWS_ACCESS_KEY_ID}
  aws_sec_key ${AWS_SECRET_ACCESS_KEY}
  region ${AWS_REGION}
  stream_name ${KINESIS_STREAM}
  debug ${KINESIS_STREAM_DEBUG}
  partition_key key
  <buffer>
    flush_interval 1
    chunk_limit_size 128k
    flush_thread_interval 0.1
    flush_thread_burst_interval 0.01
    flush_thread_count 1
  </buffer>
</match>
